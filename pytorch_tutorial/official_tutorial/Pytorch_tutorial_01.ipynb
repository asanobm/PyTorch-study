{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 빠른시작\n",
    "[LINK](https://tutorials.pytorch.kr/beginner/basics/quickstart_tutorial.html)\n",
    "\n",
    "이번 장에서는 기계학습의 일반적인 작업들을 위한 API를 통해 실행됩니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "845f4c3f78fb707"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T06:37:37.143292Z",
     "start_time": "2024-01-20T06:37:33.100653Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 데이터 작업하기\n",
    "\n",
    "파이토치(Pytorch)에는 *데이터 작업을 위한 기본 요소*두가지인 `torch.utils.DataLoader`와 `torch.utils.Dataset`이 있습니다. `Dataset`은 샘플과 정답(label)을 저장하고, `DataLoader`는 `Dataset`을 샘플에 쉽게 접근할 수 있도록 순회 가능한 객체(iterable)로 감쌉니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5581e8cc91a92a6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "PyTorch는 *TorchText*, *TorchVision*, *TorchAudio*, *TorchScatter*와 같이 도메인 특화 라이브러리를 위한 몇가지 도구를 제공합니다. 이 튜토리얼에서는 *TorchVision*의 몇가지 기능을 사용합니다.\n",
    "\n",
    "`torchvision.datasets`모듈은 CIFAR, COCO등과 같은 다양한 실제 비전(vision)데이터에 대한 `Dataset`을 포함하고 있습니다. 이 튜토리얼에서는 FasionMNIST 데이터셋을 사용합니다. 모든 TorchVision `Dataset`들은 샘플과 정답을 각각 변경하기 위한 `transform`과 `target_transform`을 인자로 받을 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6fa3ebfda27ab98b"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T06:37:37.155969Z",
     "start_time": "2024-01-20T06:37:37.142685Z"
    }
   },
   "id": "7e8efb4975e2f2cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "`Dataset`을 `DataLoader`의 인자로 전달합니다. 이는 `Dataset`을 순회 가능한 객체(iterable)로 감싸고, 자동화된 배치(batch), 샘플링(sampling), 섞기(shuffle), 병렬 처리를 지원합니다. 여기서 배치 크기(batch size)는 튜토리얼의 편의를 위해 작은 값으로 설정합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16141fbf9cec2f21"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 9 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# show test data image and label 9 times\n",
    "fig, axs = plt.subplots(3, 3, figsize=(10, 10))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        axs[i, j].imshow(test_data[i+j][0].squeeze(), cmap='gray')\n",
    "        axs[i, j].set_title(test_data[i+j][1])\n",
    "        axs[i, j].axis('off')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T08:03:31.155958Z",
     "start_time": "2024-01-20T08:03:31.001643Z"
    }
   },
   "id": "168bb7eef24333cd",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T06:37:37.162988Z",
     "start_time": "2024-01-20T06:37:37.156682Z"
    }
   },
   "id": "e3834e2d0acb9655"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 모델 만들기\n",
    "\n",
    "PyTorch에서 신경망 모델은 *nn.Module**을 상속받는 클래스(class)를 생성하여 정의합니다. `__init__`함수에서 신경망의 계층(layer)들을 정의하고 `forward`함수에서 신경망에 데이터를 어떻게 전달할지 지정합니다. 가능한 경우 GPU또는 MPS로 신경망을 이동시켜 연산을 가속(accelerate)할 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89a2ec78b62369c9"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M1 Mac:  True\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"mps\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"M1 Mac: \", torch.backends.mps.is_built())\n",
    "print(\"Using {} device\".format(device))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T08:09:13.966699Z",
     "start_time": "2024-01-20T08:09:13.962334Z"
    }
   },
   "id": "a1188e61ac54dadd"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T06:37:37.196511Z",
     "start_time": "2024-01-20T06:37:37.167824Z"
    }
   },
   "id": "258a11687a3cecea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 모델 매개변수 최적화하기\n",
    "\n",
    "모델을 학습하려면 손실 함수(loss function)와 옵티마이저(optimizer)가 필요합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28fc54f6cb78aa38"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T06:37:37.196873Z",
     "start_time": "2024-01-20T06:37:37.172775Z"
    }
   },
   "id": "b7a6eedb5a348faf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "각 학습 단계(training loop)에서 모델은 (배치(batch)로 제공되는)학습 데이터셋에 대한 예측을 수행하고, 예측 오류를 역전파하여 모델의 매개변수를 조정합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1239edf5f529beb1"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch & 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T06:37:37.197199Z",
     "start_time": "2024-01-20T06:37:37.175855Z"
    }
   },
   "id": "6768afe99e75faf1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "모델이 학습하고 있는지를 확인하기 위해 테스트 데이터셋으로 모델의 성능을 확인합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9191a6a26e6d2d2c"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T06:37:37.197852Z",
     "start_time": "2024-01-20T06:37:37.178674Z"
    }
   },
   "id": "cb59a6842540a3d2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "학습 단계는 여러번의 반복단계(epoch)로 이루어집니다. 각 epoch에서는 모델은 더 나은 예측을 하기 위해 매개변수를 학습합니다. 각 `epoch`마다 모델의 정확도(accuracy)와 손실(loss)을 출력합니다. `epoch`마다 정확도가 증가하고 손실이 감소하는 것을 보려고 합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cd0300443390c58"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.302672 [    0/60000]\n",
      "loss: 2.304448 [   64/60000]\n",
      "loss: 2.294259 [  128/60000]\n",
      "loss: 2.295219 [  192/60000]\n",
      "loss: 2.299822 [  512/60000]\n",
      "loss: 2.296094 [  576/60000]\n",
      "loss: 2.297063 [  640/60000]\n",
      "loss: 2.295778 [  704/60000]\n",
      "loss: 2.303056 [ 1024/60000]\n",
      "loss: 2.306709 [ 1088/60000]\n",
      "loss: 2.296635 [ 1152/60000]\n",
      "loss: 2.298655 [ 1216/60000]\n",
      "loss: 2.302291 [ 1536/60000]\n",
      "loss: 2.304717 [ 1600/60000]\n",
      "loss: 2.289470 [ 1664/60000]\n",
      "loss: 2.295907 [ 1728/60000]\n",
      "loss: 2.299078 [ 8192/60000]\n",
      "loss: 2.288045 [ 8256/60000]\n",
      "loss: 2.287491 [ 8320/60000]\n",
      "loss: 2.301056 [ 8384/60000]\n",
      "loss: 2.292219 [ 8704/60000]\n",
      "loss: 2.291851 [ 8768/60000]\n",
      "loss: 2.288779 [ 8832/60000]\n",
      "loss: 2.283998 [ 8896/60000]\n",
      "loss: 2.280465 [ 9216/60000]\n",
      "loss: 2.288601 [ 9280/60000]\n",
      "loss: 2.276414 [ 9344/60000]\n",
      "loss: 2.296964 [ 9408/60000]\n",
      "loss: 2.286409 [ 9728/60000]\n",
      "loss: 2.289372 [ 9792/60000]\n",
      "loss: 2.287019 [ 9856/60000]\n",
      "loss: 2.297654 [ 9920/60000]\n",
      "loss: 2.274833 [16384/60000]\n",
      "loss: 2.274919 [16448/60000]\n",
      "loss: 2.269112 [16512/60000]\n",
      "loss: 2.279617 [16576/60000]\n",
      "loss: 2.281737 [16896/60000]\n",
      "loss: 2.278801 [16960/60000]\n",
      "loss: 2.280973 [17024/60000]\n",
      "loss: 2.276112 [17088/60000]\n",
      "loss: 2.272550 [17408/60000]\n",
      "loss: 2.268533 [17472/60000]\n",
      "loss: 2.271103 [17536/60000]\n",
      "loss: 2.287270 [17600/60000]\n",
      "loss: 2.278891 [17920/60000]\n",
      "loss: 2.268746 [17984/60000]\n",
      "loss: 2.278323 [18048/60000]\n",
      "loss: 2.288656 [18112/60000]\n",
      "loss: 2.258110 [24576/60000]\n",
      "loss: 2.270057 [24640/60000]\n",
      "loss: 2.271906 [24704/60000]\n",
      "loss: 2.268605 [24768/60000]\n",
      "loss: 2.265636 [25088/60000]\n",
      "loss: 2.266964 [25152/60000]\n",
      "loss: 2.265255 [25216/60000]\n",
      "loss: 2.254264 [25280/60000]\n",
      "loss: 2.265663 [25600/60000]\n",
      "loss: 2.247184 [25664/60000]\n",
      "loss: 2.273623 [25728/60000]\n",
      "loss: 2.260633 [25792/60000]\n",
      "loss: 2.278103 [26112/60000]\n",
      "loss: 2.268655 [26176/60000]\n",
      "loss: 2.278566 [26240/60000]\n",
      "loss: 2.283612 [26304/60000]\n",
      "loss: 2.260481 [32768/60000]\n",
      "loss: 2.255491 [32832/60000]\n",
      "loss: 2.259729 [32896/60000]\n",
      "loss: 2.268970 [32960/60000]\n",
      "loss: 2.254973 [33280/60000]\n",
      "loss: 2.252759 [33344/60000]\n",
      "loss: 2.259457 [33408/60000]\n",
      "loss: 2.250318 [33472/60000]\n",
      "loss: 2.256441 [33792/60000]\n",
      "loss: 2.258021 [33856/60000]\n",
      "loss: 2.270971 [33920/60000]\n",
      "loss: 2.251656 [33984/60000]\n",
      "loss: 2.249953 [34304/60000]\n",
      "loss: 2.255398 [34368/60000]\n",
      "loss: 2.271047 [34432/60000]\n",
      "loss: 2.256074 [34496/60000]\n",
      "loss: 2.264447 [40960/60000]\n",
      "loss: 2.260989 [41024/60000]\n",
      "loss: 2.237125 [41088/60000]\n",
      "loss: 2.229322 [41152/60000]\n",
      "loss: 2.251790 [41472/60000]\n",
      "loss: 2.243930 [41536/60000]\n",
      "loss: 2.247656 [41600/60000]\n",
      "loss: 2.251338 [41664/60000]\n",
      "loss: 2.228918 [41984/60000]\n",
      "loss: 2.235546 [42048/60000]\n",
      "loss: 2.238273 [42112/60000]\n",
      "loss: 2.246406 [42176/60000]\n",
      "loss: 2.238247 [42496/60000]\n",
      "loss: 2.230712 [42560/60000]\n",
      "loss: 2.238997 [42624/60000]\n",
      "loss: 2.267502 [42688/60000]\n",
      "loss: 2.241923 [49152/60000]\n",
      "loss: 2.232727 [49216/60000]\n",
      "loss: 2.253891 [49280/60000]\n",
      "loss: 2.219136 [49344/60000]\n",
      "loss: 2.253678 [49664/60000]\n",
      "loss: 2.226336 [49728/60000]\n",
      "loss: 2.210495 [49792/60000]\n",
      "loss: 2.234300 [49856/60000]\n",
      "loss: 2.251425 [50176/60000]\n",
      "loss: 2.251225 [50240/60000]\n",
      "loss: 2.239766 [50304/60000]\n",
      "loss: 2.217334 [50368/60000]\n",
      "loss: 2.238370 [50688/60000]\n",
      "loss: 2.240662 [50752/60000]\n",
      "loss: 2.250498 [50816/60000]\n",
      "loss: 2.245796 [50880/60000]\n",
      "loss: 2.220665 [57344/60000]\n",
      "loss: 2.219843 [57408/60000]\n",
      "loss: 2.237529 [57472/60000]\n",
      "loss: 2.218779 [57536/60000]\n",
      "loss: 2.208859 [57856/60000]\n",
      "loss: 2.206322 [57920/60000]\n",
      "loss: 2.217422 [57984/60000]\n",
      "loss: 2.225140 [58048/60000]\n",
      "loss: 2.226664 [58368/60000]\n",
      "loss: 2.229298 [58432/60000]\n",
      "loss: 2.243802 [58496/60000]\n",
      "loss: 2.229460 [58560/60000]\n",
      "loss: 2.226908 [58880/60000]\n",
      "loss: 2.229987 [58944/60000]\n",
      "loss: 2.227931 [59008/60000]\n",
      "loss: 2.223428 [59072/60000]\n",
      "Test Error: \n",
      " Accuracy: 37.6%, Avg loss: 2.220831 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.223094 [    0/60000]\n",
      "loss: 2.215615 [   64/60000]\n",
      "loss: 2.223742 [  128/60000]\n",
      "loss: 2.227586 [  192/60000]\n",
      "loss: 2.216849 [  512/60000]\n",
      "loss: 2.226717 [  576/60000]\n",
      "loss: 2.209959 [  640/60000]\n",
      "loss: 2.200180 [  704/60000]\n",
      "loss: 2.211879 [ 1024/60000]\n",
      "loss: 2.235615 [ 1088/60000]\n",
      "loss: 2.211903 [ 1152/60000]\n",
      "loss: 2.220111 [ 1216/60000]\n",
      "loss: 2.201612 [ 1536/60000]\n",
      "loss: 2.214653 [ 1600/60000]\n",
      "loss: 2.189101 [ 1664/60000]\n",
      "loss: 2.220994 [ 1728/60000]\n",
      "loss: 2.232142 [ 8192/60000]\n",
      "loss: 2.193136 [ 8256/60000]\n",
      "loss: 2.199261 [ 8320/60000]\n",
      "loss: 2.226354 [ 8384/60000]\n",
      "loss: 2.210905 [ 8704/60000]\n",
      "loss: 2.208929 [ 8768/60000]\n",
      "loss: 2.230250 [ 8832/60000]\n",
      "loss: 2.202536 [ 8896/60000]\n",
      "loss: 2.186202 [ 9216/60000]\n",
      "loss: 2.193275 [ 9280/60000]\n",
      "loss: 2.178437 [ 9344/60000]\n",
      "loss: 2.238248 [ 9408/60000]\n",
      "loss: 2.204440 [ 9728/60000]\n",
      "loss: 2.209231 [ 9792/60000]\n",
      "loss: 2.187151 [ 9856/60000]\n",
      "loss: 2.224274 [ 9920/60000]\n",
      "loss: 2.195238 [16384/60000]\n",
      "loss: 2.168803 [16448/60000]\n",
      "loss: 2.149010 [16512/60000]\n",
      "loss: 2.175602 [16576/60000]\n",
      "loss: 2.196678 [16896/60000]\n",
      "loss: 2.213329 [16960/60000]\n",
      "loss: 2.200359 [17024/60000]\n",
      "loss: 2.195115 [17088/60000]\n",
      "loss: 2.176099 [17408/60000]\n",
      "loss: 2.180776 [17472/60000]\n",
      "loss: 2.154302 [17536/60000]\n",
      "loss: 2.221979 [17600/60000]\n",
      "loss: 2.200729 [17920/60000]\n",
      "loss: 2.182615 [17984/60000]\n",
      "loss: 2.202460 [18048/60000]\n",
      "loss: 2.226214 [18112/60000]\n",
      "loss: 2.147235 [24576/60000]\n",
      "loss: 2.182719 [24640/60000]\n",
      "loss: 2.182995 [24704/60000]\n",
      "loss: 2.172361 [24768/60000]\n",
      "loss: 2.181552 [25088/60000]\n",
      "loss: 2.172429 [25152/60000]\n",
      "loss: 2.154363 [25216/60000]\n",
      "loss: 2.123733 [25280/60000]\n",
      "loss: 2.158393 [25600/60000]\n",
      "loss: 2.134451 [25664/60000]\n",
      "loss: 2.184113 [25728/60000]\n",
      "loss: 2.160172 [25792/60000]\n",
      "loss: 2.200255 [26112/60000]\n",
      "loss: 2.172065 [26176/60000]\n",
      "loss: 2.206012 [26240/60000]\n",
      "loss: 2.211523 [26304/60000]\n",
      "loss: 2.172589 [32768/60000]\n",
      "loss: 2.154609 [32832/60000]\n",
      "loss: 2.149315 [32896/60000]\n",
      "loss: 2.188055 [32960/60000]\n",
      "loss: 2.139569 [33280/60000]\n",
      "loss: 2.130201 [33344/60000]\n",
      "loss: 2.155477 [33408/60000]\n",
      "loss: 2.139706 [33472/60000]\n",
      "loss: 2.147556 [33792/60000]\n",
      "loss: 2.150348 [33856/60000]\n",
      "loss: 2.195205 [33920/60000]\n",
      "loss: 2.143702 [33984/60000]\n",
      "loss: 2.131685 [34304/60000]\n",
      "loss: 2.159013 [34368/60000]\n",
      "loss: 2.168498 [34432/60000]\n",
      "loss: 2.129495 [34496/60000]\n",
      "loss: 2.168149 [40960/60000]\n",
      "loss: 2.166959 [41024/60000]\n",
      "loss: 2.102335 [41088/60000]\n",
      "loss: 2.082863 [41152/60000]\n",
      "loss: 2.151134 [41472/60000]\n",
      "loss: 2.137231 [41536/60000]\n",
      "loss: 2.134260 [41600/60000]\n",
      "loss: 2.144994 [41664/60000]\n",
      "loss: 2.110080 [41984/60000]\n",
      "loss: 2.122481 [42048/60000]\n",
      "loss: 2.109351 [42112/60000]\n",
      "loss: 2.143149 [42176/60000]\n",
      "loss: 2.125386 [42496/60000]\n",
      "loss: 2.085492 [42560/60000]\n",
      "loss: 2.110492 [42624/60000]\n",
      "loss: 2.174846 [42688/60000]\n",
      "loss: 2.127970 [49152/60000]\n",
      "loss: 2.104657 [49216/60000]\n",
      "loss: 2.153845 [49280/60000]\n",
      "loss: 2.063529 [49344/60000]\n",
      "loss: 2.136468 [49664/60000]\n",
      "loss: 2.096798 [49728/60000]\n",
      "loss: 2.057160 [49792/60000]\n",
      "loss: 2.100276 [49856/60000]\n",
      "loss: 2.145005 [50176/60000]\n",
      "loss: 2.154454 [50240/60000]\n",
      "loss: 2.139696 [50304/60000]\n",
      "loss: 2.063565 [50368/60000]\n",
      "loss: 2.109544 [50688/60000]\n",
      "loss: 2.129504 [50752/60000]\n",
      "loss: 2.130670 [50816/60000]\n",
      "loss: 2.135868 [50880/60000]\n",
      "loss: 2.079462 [57344/60000]\n",
      "loss: 2.064994 [57408/60000]\n",
      "loss: 2.108972 [57472/60000]\n",
      "loss: 2.087134 [57536/60000]\n",
      "loss: 2.060860 [57856/60000]\n",
      "loss: 2.035886 [57920/60000]\n",
      "loss: 2.087198 [57984/60000]\n",
      "loss: 2.107589 [58048/60000]\n",
      "loss: 2.091096 [58368/60000]\n",
      "loss: 2.127399 [58432/60000]\n",
      "loss: 2.130913 [58496/60000]\n",
      "loss: 2.098819 [58560/60000]\n",
      "loss: 2.101181 [58880/60000]\n",
      "loss: 2.084610 [58944/60000]\n",
      "loss: 2.095202 [59008/60000]\n",
      "loss: 2.078722 [59072/60000]\n",
      "Test Error: \n",
      " Accuracy: 39.6%, Avg loss: 2.084391 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.100515 [    0/60000]\n",
      "loss: 2.053918 [   64/60000]\n",
      "loss: 2.096573 [  128/60000]\n",
      "loss: 2.110043 [  192/60000]\n",
      "loss: 2.076293 [  512/60000]\n",
      "loss: 2.106141 [  576/60000]\n",
      "loss: 2.039719 [  640/60000]\n",
      "loss: 2.028514 [  704/60000]\n",
      "loss: 2.050974 [ 1024/60000]\n",
      "loss: 2.116500 [ 1088/60000]\n",
      "loss: 2.074862 [ 1152/60000]\n",
      "loss: 2.100931 [ 1216/60000]\n",
      "loss: 2.031865 [ 1536/60000]\n",
      "loss: 2.046687 [ 1600/60000]\n",
      "loss: 2.011790 [ 1664/60000]\n",
      "loss: 2.095844 [ 1728/60000]\n",
      "loss: 2.130996 [ 8192/60000]\n",
      "loss: 2.019197 [ 8256/60000]\n",
      "loss: 2.042507 [ 8320/60000]\n",
      "loss: 2.096750 [ 8384/60000]\n",
      "loss: 2.062879 [ 8704/60000]\n",
      "loss: 2.066052 [ 8768/60000]\n",
      "loss: 2.123697 [ 8832/60000]\n",
      "loss: 2.066150 [ 8896/60000]\n",
      "loss: 2.019378 [ 9216/60000]\n",
      "loss: 2.023466 [ 9280/60000]\n",
      "loss: 2.010250 [ 9344/60000]\n",
      "loss: 2.125435 [ 9408/60000]\n",
      "loss: 2.045166 [ 9728/60000]\n",
      "loss: 2.077581 [ 9792/60000]\n",
      "loss: 2.015911 [ 9856/60000]\n",
      "loss: 2.104620 [ 9920/60000]\n",
      "loss: 2.060399 [16384/60000]\n",
      "loss: 1.980302 [16448/60000]\n",
      "loss: 1.938429 [16512/60000]\n",
      "loss: 1.996792 [16576/60000]\n",
      "loss: 2.026359 [16896/60000]\n",
      "loss: 2.077583 [16960/60000]\n",
      "loss: 2.046139 [17024/60000]\n",
      "loss: 2.053555 [17088/60000]\n",
      "loss: 2.016833 [17408/60000]\n",
      "loss: 2.019353 [17472/60000]\n",
      "loss: 1.945283 [17536/60000]\n",
      "loss: 2.102083 [17600/60000]\n",
      "loss: 2.057381 [17920/60000]\n",
      "loss: 2.028298 [17984/60000]\n",
      "loss: 2.072432 [18048/60000]\n",
      "loss: 2.107086 [18112/60000]\n",
      "loss: 1.939072 [24576/60000]\n",
      "loss: 2.009123 [24640/60000]\n",
      "loss: 2.020042 [24704/60000]\n",
      "loss: 1.997813 [24768/60000]\n",
      "loss: 2.011377 [25088/60000]\n",
      "loss: 1.973609 [25152/60000]\n",
      "loss: 1.938847 [25216/60000]\n",
      "loss: 1.887359 [25280/60000]\n",
      "loss: 1.956184 [25600/60000]\n",
      "loss: 1.930627 [25664/60000]\n",
      "loss: 2.011218 [25728/60000]\n",
      "loss: 1.981842 [25792/60000]\n",
      "loss: 2.054797 [26112/60000]\n",
      "loss: 1.992240 [26176/60000]\n",
      "loss: 2.053674 [26240/60000]\n",
      "loss: 2.076353 [26304/60000]\n",
      "loss: 2.018236 [32768/60000]\n",
      "loss: 1.970253 [32832/60000]\n",
      "loss: 1.937892 [32896/60000]\n",
      "loss: 2.044074 [32960/60000]\n",
      "loss: 1.919513 [33280/60000]\n",
      "loss: 1.912512 [33344/60000]\n",
      "loss: 1.956095 [33408/60000]\n",
      "loss: 1.946071 [33472/60000]\n",
      "loss: 1.941980 [33792/60000]\n",
      "loss: 1.953929 [33856/60000]\n",
      "loss: 2.048321 [33920/60000]\n",
      "loss: 1.944145 [33984/60000]\n",
      "loss: 1.925141 [34304/60000]\n",
      "loss: 1.982730 [34368/60000]\n",
      "loss: 1.967545 [34432/60000]\n",
      "loss: 1.894117 [34496/60000]\n",
      "loss: 1.989215 [40960/60000]\n",
      "loss: 2.007869 [41024/60000]\n",
      "loss: 1.863918 [41088/60000]\n",
      "loss: 1.824334 [41152/60000]\n",
      "loss: 1.976076 [41472/60000]\n",
      "loss: 1.947418 [41536/60000]\n",
      "loss: 1.935184 [41600/60000]\n",
      "loss: 1.957875 [41664/60000]\n",
      "loss: 1.909183 [41984/60000]\n",
      "loss: 1.934545 [42048/60000]\n",
      "loss: 1.875098 [42112/60000]\n",
      "loss: 1.965940 [42176/60000]\n",
      "loss: 1.935364 [42496/60000]\n",
      "loss: 1.820145 [42560/60000]\n",
      "loss: 1.880460 [42624/60000]\n",
      "loss: 2.013028 [42688/60000]\n",
      "loss: 1.933374 [49152/60000]\n",
      "loss: 1.890138 [49216/60000]\n",
      "loss: 1.983945 [49280/60000]\n",
      "loss: 1.801828 [49344/60000]\n",
      "loss: 1.919881 [49664/60000]\n",
      "loss: 1.876822 [49728/60000]\n",
      "loss: 1.798802 [49792/60000]\n",
      "loss: 1.875392 [49856/60000]\n",
      "loss: 1.959511 [50176/60000]\n",
      "loss: 1.986360 [50240/60000]\n",
      "loss: 1.976487 [50304/60000]\n",
      "loss: 1.800822 [50368/60000]\n",
      "loss: 1.886114 [50688/60000]\n",
      "loss: 1.945800 [50752/60000]\n",
      "loss: 1.926420 [50816/60000]\n",
      "loss: 1.955874 [50880/60000]\n",
      "loss: 1.849110 [57344/60000]\n",
      "loss: 1.804547 [57408/60000]\n",
      "loss: 1.893886 [57472/60000]\n",
      "loss: 1.872110 [57536/60000]\n",
      "loss: 1.815178 [57856/60000]\n",
      "loss: 1.749750 [57920/60000]\n",
      "loss: 1.873130 [57984/60000]\n",
      "loss: 1.925557 [58048/60000]\n",
      "loss: 1.870832 [58368/60000]\n",
      "loss: 1.971628 [58432/60000]\n",
      "loss: 1.939683 [58496/60000]\n",
      "loss: 1.880222 [58560/60000]\n",
      "loss: 1.896154 [58880/60000]\n",
      "loss: 1.845423 [58944/60000]\n",
      "loss: 1.880516 [59008/60000]\n",
      "loss: 1.834123 [59072/60000]\n",
      "Test Error: \n",
      " Accuracy: 45.2%, Avg loss: 1.865868 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.907389 [    0/60000]\n",
      "loss: 1.789085 [   64/60000]\n",
      "loss: 1.895399 [  128/60000]\n",
      "loss: 1.921025 [  192/60000]\n",
      "loss: 1.865079 [  512/60000]\n",
      "loss: 1.920631 [  576/60000]\n",
      "loss: 1.758336 [  640/60000]\n",
      "loss: 1.753621 [  704/60000]\n",
      "loss: 1.790199 [ 1024/60000]\n",
      "loss: 1.929158 [ 1088/60000]\n",
      "loss: 1.861745 [ 1152/60000]\n",
      "loss: 1.923190 [ 1216/60000]\n",
      "loss: 1.761407 [ 1536/60000]\n",
      "loss: 1.776980 [ 1600/60000]\n",
      "loss: 1.732191 [ 1664/60000]\n",
      "loss: 1.898841 [ 1728/60000]\n",
      "loss: 1.982477 [ 8192/60000]\n",
      "loss: 1.761002 [ 8256/60000]\n",
      "loss: 1.807957 [ 8320/60000]\n",
      "loss: 1.906888 [ 8384/60000]\n",
      "loss: 1.845528 [ 8704/60000]\n",
      "loss: 1.854429 [ 8768/60000]\n",
      "loss: 1.961591 [ 8832/60000]\n",
      "loss: 1.872352 [ 8896/60000]\n",
      "loss: 1.776272 [ 9216/60000]\n",
      "loss: 1.768220 [ 9280/60000]\n",
      "loss: 1.768029 [ 9344/60000]\n",
      "loss: 1.960963 [ 9408/60000]\n",
      "loss: 1.815164 [ 9728/60000]\n",
      "loss: 1.877487 [ 9792/60000]\n",
      "loss: 1.758578 [ 9856/60000]\n",
      "loss: 1.934468 [ 9920/60000]\n",
      "loss: 1.871923 [16384/60000]\n",
      "loss: 1.710550 [16448/60000]\n",
      "loss: 1.651231 [16512/60000]\n",
      "loss: 1.751745 [16576/60000]\n",
      "loss: 1.781007 [16896/60000]\n",
      "loss: 1.890046 [16960/60000]\n",
      "loss: 1.825670 [17024/60000]\n",
      "loss: 1.859293 [17088/60000]\n",
      "loss: 1.798331 [17408/60000]\n",
      "loss: 1.796881 [17472/60000]\n",
      "loss: 1.635656 [17536/60000]\n",
      "loss: 1.939809 [17600/60000]\n",
      "loss: 1.859917 [17920/60000]\n",
      "loss: 1.817851 [17984/60000]\n",
      "loss: 1.897006 [18048/60000]\n",
      "loss: 1.949208 [18112/60000]\n",
      "loss: 1.666911 [24576/60000]\n",
      "loss: 1.775122 [24640/60000]\n",
      "loss: 1.806443 [24704/60000]\n",
      "loss: 1.771400 [24768/60000]\n",
      "loss: 1.773240 [25088/60000]\n",
      "loss: 1.705044 [25152/60000]\n",
      "loss: 1.656364 [25216/60000]\n",
      "loss: 1.574725 [25280/60000]\n",
      "loss: 1.701107 [25600/60000]\n",
      "loss: 1.657805 [25664/60000]\n",
      "loss: 1.785818 [25728/60000]\n",
      "loss: 1.745934 [25792/60000]\n",
      "loss: 1.869726 [26112/60000]\n",
      "loss: 1.765753 [26176/60000]\n",
      "loss: 1.858868 [26240/60000]\n",
      "loss: 1.909568 [26304/60000]\n",
      "loss: 1.825293 [32768/60000]\n",
      "loss: 1.749839 [32832/60000]\n",
      "loss: 1.680663 [32896/60000]\n",
      "loss: 1.887325 [32960/60000]\n",
      "loss: 1.642771 [33280/60000]\n",
      "loss: 1.663983 [33344/60000]\n",
      "loss: 1.700719 [33408/60000]\n",
      "loss: 1.720963 [33472/60000]\n",
      "loss: 1.684557 [33792/60000]\n",
      "loss: 1.721909 [33856/60000]\n",
      "loss: 1.870642 [33920/60000]\n",
      "loss: 1.694397 [33984/60000]\n",
      "loss: 1.694344 [34304/60000]\n",
      "loss: 1.766815 [34368/60000]\n",
      "loss: 1.715619 [34432/60000]\n",
      "loss: 1.611246 [34496/60000]\n",
      "loss: 1.783507 [40960/60000]\n",
      "loss: 1.838194 [41024/60000]\n",
      "loss: 1.601372 [41088/60000]\n",
      "loss: 1.541533 [41152/60000]\n",
      "loss: 1.780464 [41472/60000]\n",
      "loss: 1.730261 [41536/60000]\n",
      "loss: 1.716504 [41600/60000]\n",
      "loss: 1.761479 [41664/60000]\n",
      "loss: 1.691215 [41984/60000]\n",
      "loss: 1.740055 [42048/60000]\n",
      "loss: 1.601560 [42112/60000]\n",
      "loss: 1.764717 [42176/60000]\n",
      "loss: 1.731054 [42496/60000]\n",
      "loss: 1.532728 [42560/60000]\n",
      "loss: 1.625087 [42624/60000]\n",
      "loss: 1.855787 [42688/60000]\n",
      "loss: 1.716011 [49152/60000]\n",
      "loss: 1.669174 [49216/60000]\n",
      "loss: 1.813294 [49280/60000]\n",
      "loss: 1.547592 [49344/60000]\n",
      "loss: 1.673459 [49664/60000]\n",
      "loss: 1.650043 [49728/60000]\n",
      "loss: 1.550265 [49792/60000]\n",
      "loss: 1.653635 [49856/60000]\n",
      "loss: 1.768016 [50176/60000]\n",
      "loss: 1.816588 [50240/60000]\n",
      "loss: 1.801387 [50304/60000]\n",
      "loss: 1.530424 [50368/60000]\n",
      "loss: 1.652893 [50688/60000]\n",
      "loss: 1.770105 [50752/60000]\n",
      "loss: 1.736173 [50816/60000]\n",
      "loss: 1.784044 [50880/60000]\n",
      "loss: 1.632680 [57344/60000]\n",
      "loss: 1.539121 [57408/60000]\n",
      "loss: 1.682511 [57472/60000]\n",
      "loss: 1.670618 [57536/60000]\n",
      "loss: 1.576438 [57856/60000]\n",
      "loss: 1.477682 [57920/60000]\n",
      "loss: 1.665486 [57984/60000]\n",
      "loss: 1.765813 [58048/60000]\n",
      "loss: 1.666098 [58368/60000]\n",
      "loss: 1.830834 [58432/60000]\n",
      "loss: 1.736724 [58496/60000]\n",
      "loss: 1.668847 [58560/60000]\n",
      "loss: 1.704815 [58880/60000]\n",
      "loss: 1.616592 [58944/60000]\n",
      "loss: 1.683318 [59008/60000]\n",
      "loss: 1.592403 [59072/60000]\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 1.665561 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.728859 [    0/60000]\n",
      "loss: 1.556525 [   64/60000]\n",
      "loss: 1.714165 [  128/60000]\n",
      "loss: 1.730116 [  192/60000]\n",
      "loss: 1.699446 [  512/60000]\n",
      "loss: 1.764993 [  576/60000]\n",
      "loss: 1.493191 [  640/60000]\n",
      "loss: 1.497508 [  704/60000]\n",
      "loss: 1.553320 [ 1024/60000]\n",
      "loss: 1.768195 [ 1088/60000]\n",
      "loss: 1.672794 [ 1152/60000]\n",
      "loss: 1.762930 [ 1216/60000]\n",
      "loss: 1.526449 [ 1536/60000]\n",
      "loss: 1.527863 [ 1600/60000]\n",
      "loss: 1.500882 [ 1664/60000]\n",
      "loss: 1.722749 [ 1728/60000]\n",
      "loss: 1.847194 [ 8192/60000]\n",
      "loss: 1.545109 [ 8256/60000]\n",
      "loss: 1.606164 [ 8320/60000]\n",
      "loss: 1.746467 [ 8384/60000]\n",
      "loss: 1.668240 [ 8704/60000]\n",
      "loss: 1.675446 [ 8768/60000]\n",
      "loss: 1.815296 [ 8832/60000]\n",
      "loss: 1.722562 [ 8896/60000]\n",
      "loss: 1.582006 [ 9216/60000]\n",
      "loss: 1.545557 [ 9280/60000]\n",
      "loss: 1.568408 [ 9344/60000]\n",
      "loss: 1.816757 [ 9408/60000]\n",
      "loss: 1.620531 [ 9728/60000]\n",
      "loss: 1.704286 [ 9792/60000]\n",
      "loss: 1.532862 [ 9856/60000]\n",
      "loss: 1.795672 [ 9920/60000]\n",
      "loss: 1.715223 [16384/60000]\n",
      "loss: 1.491821 [16448/60000]\n",
      "loss: 1.442324 [16512/60000]\n",
      "loss: 1.573697 [16576/60000]\n",
      "loss: 1.578607 [16896/60000]\n",
      "loss: 1.734785 [16960/60000]\n",
      "loss: 1.633498 [17024/60000]\n",
      "loss: 1.699351 [17088/60000]\n",
      "loss: 1.628284 [17408/60000]\n",
      "loss: 1.633008 [17472/60000]\n",
      "loss: 1.369697 [17536/60000]\n",
      "loss: 1.817666 [17600/60000]\n",
      "loss: 1.702976 [17920/60000]\n",
      "loss: 1.649266 [17984/60000]\n",
      "loss: 1.755805 [18048/60000]\n",
      "loss: 1.833237 [18112/60000]\n",
      "loss: 1.477548 [24576/60000]\n",
      "loss: 1.586218 [24640/60000]\n",
      "loss: 1.644363 [24704/60000]\n",
      "loss: 1.603675 [24768/60000]\n",
      "loss: 1.574501 [25088/60000]\n",
      "loss: 1.487962 [25152/60000]\n",
      "loss: 1.440694 [25216/60000]\n",
      "loss: 1.349289 [25280/60000]\n",
      "loss: 1.517238 [25600/60000]\n",
      "loss: 1.450761 [25664/60000]\n",
      "loss: 1.617490 [25728/60000]\n",
      "loss: 1.558756 [25792/60000]\n",
      "loss: 1.729145 [26112/60000]\n",
      "loss: 1.610160 [26176/60000]\n",
      "loss: 1.716092 [26240/60000]\n",
      "loss: 1.788421 [26304/60000]\n",
      "loss: 1.675370 [32768/60000]\n",
      "loss: 1.598175 [32832/60000]\n",
      "loss: 1.504601 [32896/60000]\n",
      "loss: 1.790293 [32960/60000]\n",
      "loss: 1.438735 [33280/60000]\n",
      "loss: 1.505925 [33344/60000]\n",
      "loss: 1.503845 [33408/60000]\n",
      "loss: 1.574895 [33472/60000]\n",
      "loss: 1.493681 [33792/60000]\n",
      "loss: 1.569104 [33856/60000]\n",
      "loss: 1.739093 [33920/60000]\n",
      "loss: 1.515351 [33984/60000]\n",
      "loss: 1.548193 [34304/60000]\n",
      "loss: 1.614414 [34368/60000]\n",
      "loss: 1.530458 [34432/60000]\n",
      "loss: 1.416567 [34496/60000]\n",
      "loss: 1.632453 [40960/60000]\n",
      "loss: 1.727324 [41024/60000]\n",
      "loss: 1.433184 [41088/60000]\n",
      "loss: 1.354780 [41152/60000]\n",
      "loss: 1.647062 [41472/60000]\n",
      "loss: 1.573211 [41536/60000]\n",
      "loss: 1.570821 [41600/60000]\n",
      "loss: 1.645915 [41664/60000]\n",
      "loss: 1.548612 [41984/60000]\n",
      "loss: 1.619662 [42048/60000]\n",
      "loss: 1.411688 [42112/60000]\n",
      "loss: 1.620097 [42176/60000]\n",
      "loss: 1.596194 [42496/60000]\n",
      "loss: 1.353256 [42560/60000]\n",
      "loss: 1.458045 [42624/60000]\n",
      "loss: 1.761324 [42688/60000]\n",
      "loss: 1.554624 [49152/60000]\n",
      "loss: 1.523902 [49216/60000]\n",
      "loss: 1.697405 [49280/60000]\n",
      "loss: 1.398402 [49344/60000]\n",
      "loss: 1.501527 [49664/60000]\n",
      "loss: 1.500598 [49728/60000]\n",
      "loss: 1.401525 [49792/60000]\n",
      "loss: 1.517840 [49856/60000]\n",
      "loss: 1.640177 [50176/60000]\n",
      "loss: 1.704944 [50240/60000]\n",
      "loss: 1.673441 [50304/60000]\n",
      "loss: 1.351152 [50368/60000]\n",
      "loss: 1.498417 [50688/60000]\n",
      "loss: 1.660668 [50752/60000]\n",
      "loss: 1.615363 [50816/60000]\n",
      "loss: 1.674241 [50880/60000]\n",
      "loss: 1.491557 [57344/60000]\n",
      "loss: 1.356661 [57408/60000]\n",
      "loss: 1.533373 [57472/60000]\n",
      "loss: 1.543754 [57536/60000]\n",
      "loss: 1.422540 [57856/60000]\n",
      "loss: 1.307147 [57920/60000]\n",
      "loss: 1.531247 [57984/60000]\n",
      "loss: 1.667829 [58048/60000]\n",
      "loss: 1.528924 [58368/60000]\n",
      "loss: 1.734403 [58432/60000]\n",
      "loss: 1.586431 [58496/60000]\n",
      "loss: 1.527798 [58560/60000]\n",
      "loss: 1.582976 [58880/60000]\n",
      "loss: 1.467705 [58944/60000]\n",
      "loss: 1.559352 [59008/60000]\n",
      "loss: 1.430048 [59072/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.8%, Avg loss: 1.536727 \n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T06:37:51.902414Z",
     "start_time": "2024-01-20T06:37:37.181165Z"
    }
   },
   "id": "73530fbaca865d1a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 모델 저장하기\n",
    "\n",
    "모델을 저장하는 일반적인 방법은 (모델의 매개변수들을 포함햐여) 내부 상태사전(internal state dictionary)을 직렬화(serialize)하는 것입니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0c074b5c615b551"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T06:37:51.906334Z",
     "start_time": "2024-01-20T06:37:51.903369Z"
    }
   },
   "id": "da0f9ad635443418"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 모델 불러오기\n",
    "모델을 불러오는 과정에서 모델 구조를 다시 만들고 상태 사전을 모델에 불러오는 과정이 포함됩니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73ac7e1659797168"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T06:37:51.916289Z",
     "start_time": "2024-01-20T06:37:51.905977Z"
    }
   },
   "id": "17db71b8e5a41030"
  },
  {
   "cell_type": "markdown",
   "source": [
    "모델을 사용하여 예측해봅니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "521d3a7d6162f502"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T06:37:51.916960Z",
     "start_time": "2024-01-20T06:37:51.913466Z"
    }
   },
   "id": "38ae51bab773a233"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T06:37:51.921234Z",
     "start_time": "2024-01-20T06:37:51.916127Z"
    }
   },
   "id": "cb4c579b9d500faa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
